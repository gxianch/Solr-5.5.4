<?xml version="1.0" encoding="UTF-8" ?>

<!--  
  1、为了改进性能，可以采取以下几种措施：

将所有只用于搜索的，而不需要作为结果的field（特别是一些比较大的field）的stored设置为false
将不需要被用于搜索的，而只是作为结果返回的field的indexed设置为false
删除所有不必要的copyField声明
为了索引字段的最小化和搜索的效率，将所有的 text fields的index都设置成field，然后使用copyField将他们都复制到一个总的 text field上，然后对他进行搜索。
为了最大化搜索效率，使用java编写的客户端与solr交互（使用流通信）
在服务器端运行JVM（省去网络通信），使用尽可能高的Log输出等级，减少日志量。
-->

<schema name="ott" version="1.6">
       <!--field属性说明:
         filed字段用于定义数据源字段所使用的搜索类型与相关设置.
         name：数据源字段名，搜索使用到.
         type：搜索类型名例如中文ika搜索名text_ika，对应于fieldType中的name.不需要分词的字符串类型，string即可,如果需要分词，types中配置好的分词type。
         indexed：是否被索引，只有设置为true的字段才能进行搜索排序分片(earchable, sortable, facetable)。
         stored：是否存储内容，如果不需要存储字段值，尽量设置为false以提高效率。
         multiValued：是否为多值类型，SOLR允许配置多个数据源字段存储到一个搜索字段中。多个值必须为true，否则有可能抛出异常。
		 omitNorms
		•sortMissingLast = true时，那些在该<field>上没有值的documents将被排在那些在该<field>上有值的documents之后。
		•sortMissingFirst = true时的情况正好相反。
		•如果两者都设为false，则使用Lucene的排序。 

     --> 
   <field name="_version_" type="long" indexed="true" stored="true"/> 
   <field name="_root_" type="string" indexed="true" stored="false"/>   
   <!-- 支持solrCloud的implicit路由 -->
   <field name="_route_" type="string" />
 
   <field name="id" type="int" indexed="true" stored="true" required="true" multiValued="false" /> 
  <!--     <field name="name" type="namePinYin" indexed="true" stored="true" />  -->
   <field name="name" type="string" indexed="true" stored="true" />  
   <field name="year" type="int" indexed="true" stored="true" />
   <!--各文字拼音首字母 -->
   <field name="spell" type="string" indexed="true" stored="true" /> 
   <field name="column" type="int" indexed="true" stored="true" multiValued="true" /> 
   <field name="area" type="int" indexed="true" stored="true" multiValued="true" />   
   <field name="type" type="int" indexed="true" stored="true" multiValued="true" />  
   <field name="utime" type="long" indexed="true" stored="true" />
   <field name="text" type="text_general" indexed="false" stored="true" multiValued="true"/>
    
	<!-- 动态字段定义通过*来定义 
	
	如果一个field的名字没有匹配到，那么就会用动态field试图匹配定义的各种模式。
	"*"只能出现在模式的最前和最后
	较长的模式会被先去做匹配
	如果2个模式同时匹配上，最先定义的优先
	-->
   <dynamicField name="*_i"  type="int"    indexed="false"  stored="true"/>
   <dynamicField name="rand_*"  type="random"  indexed="true"  stored="false" />
   
   <!--uniqueKey节点 , 设置主键，solr必须有一个主键，一般为id也可以自行定义. 这个字段决定和增强文档的唯一性 -->
   <uniqueKey>id</uniqueKey>

   <!--defaultSearchField节点    默认搜索的字段,默认值为text,如果我们已经将需要搜索的字段拷贝至all字段了,在这里设为all即可 ,如果搜索参数中没有指定具体的field，那么这是默认的域。-->
   <defaultSearchField>name</defaultSearchField> 

   <!--solrQueryParser节点
    默认搜索操作符参数，及搜索短语间的逻辑，用AND增加准确率，用OR增加覆盖面，建议用AND，也可在搜索语句中定义。
    例如搜索"Java 多线程"，使用AND默认搜索为"Java AND 多线程"-->

   <!-- 
   配置搜索参数短语间的逻辑，可以是"AND|OR"。
   <solrQueryParser defaultOperator="OR"/> -->

	<!--copyField节点
    如果我们的搜索需要搜索多个字段该怎么办呢?这时候，我们就可以使用copyField节点,
     我们将所有的中文分词字段全部拷贝至all中，当我们进行全文检索是，只用搜索all字段就OK了.
	 
	 作用：
	将多个field的数据放在一起同时搜索，提供速度
	将一个field的数据拷贝到另一个，可以用2种不同的方式来建立索引。
	--> 
	<!--
	   <copyField source="mediaInfoName" dest="all"/> 
	   <copyField source="mediaInfoName" dest="mediaInfoName_pinyin"/>
	 -->
  <!--定义字段处理类型  -->
 
    <fieldType name="string" class="solr.StrField" sortMissingLast="true" />
    <fieldType name="boolean" class="solr.BoolField" sortMissingLast="true"/>
    <fieldType name="int" class="solr.TrieIntField" precisionStep="0" positionIncrementGap="0"/>
    <fieldType name="float" class="solr.TrieFloatField" precisionStep="0" positionIncrementGap="0"/>
    <fieldType name="long" class="solr.TrieLongField" precisionStep="0" positionIncrementGap="0"/>
    <fieldType name="double" class="solr.TrieDoubleField" precisionStep="0" positionIncrementGap="0"/>
    <fieldType name="tint" class="solr.TrieIntField" precisionStep="8" positionIncrementGap="0"/>
    <fieldType name="tfloat" class="solr.TrieFloatField" precisionStep="8" positionIncrementGap="0"/>
    <fieldType name="tlong" class="solr.TrieLongField" precisionStep="8" positionIncrementGap="0"/>
    <fieldType name="tdouble" class="solr.TrieDoubleField" precisionStep="8" positionIncrementGap="0"/>
    <fieldType name="date" class="solr.TrieDateField" precisionStep="0" positionIncrementGap="0"/>
    <fieldType name="tdate" class="solr.TrieDateField" precisionStep="6" positionIncrementGap="0"/>
    <fieldType name="binary" class="solr.BinaryField"/>
    <fieldType name="random" class="solr.RandomSortField" indexed="true" />
    <fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
      <analyzer>
        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
      </analyzer>
    </fieldType>
    <fieldType name="text_general" class="solr.TextField" positionIncrementGap="100">
      <analyzer type="index">
        <tokenizer class="solr.StandardTokenizerFactory"/>
        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt" />
        <filter class="solr.LowerCaseFilterFactory"/>
      </analyzer>
      <analyzer type="query">
        <tokenizer class="solr.StandardTokenizerFactory"/>
		<!-- 在禁用字（stopword）删除后，在短语间增加间隔 stopword：即在建立索引过程中（建立索引和搜索）被忽略的词，比如is this等常用词。在conf/stopwords.txt维护。-->
        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt" />
        <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>
        <filter class="solr.LowerCaseFilterFactory"/>
      </analyzer>
    </fieldType>
    <fieldType name="text_en" class="solr.TextField" positionIncrementGap="100">
      <analyzer type="index">
        <tokenizer class="solr.StandardTokenizerFactory"/>
        <filter class="solr.StopFilterFactory"
                ignoreCase="true"
                words="lang/stopwords_en.txt"
                />
        <filter class="solr.LowerCaseFilterFactory"/>
		<filter class="solr.EnglishPossessiveFilterFactory"/>
        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
        <filter class="solr.PorterStemFilterFactory"/>
      </analyzer>
      <analyzer type="query">
        <tokenizer class="solr.StandardTokenizerFactory"/>
        <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>
        <filter class="solr.StopFilterFactory"
                ignoreCase="true"
                words="lang/stopwords_en.txt"
                />
        <filter class="solr.LowerCaseFilterFactory"/>
	<filter class="solr.EnglishPossessiveFilterFactory"/>
        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
	<!-- Optionally you may want to use this less aggressive stemmer instead of PorterStemFilterFactory:
        <filter class="solr.EnglishMinimalStemFilterFactory"/>
	-->
        <filter class="solr.PorterStemFilterFactory"/>
      </analyzer>
    </fieldType>
 
    <fieldType name="text_en_splitting" class="solr.TextField" positionIncrementGap="100" autoGeneratePhraseQueries="true">
      <analyzer type="index">
	  <!--这个分词包是空格分词，在向索引库添加text类型的索引时，Solr会首先用空格进行分词  
         然后把分词结果依次使用指定的过滤器进行过滤，最后剩下的结果，才会加入到索引库中以备查询。  
      注意:Solr的analysis包并没有带支持中文的包，需要自己添加中文分词器，google下。    
     -->   
		<!-- 空格分词，精确匹配。 -->
        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
        <!-- in this example, we will only use synonyms at query time
        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
        -->
        <!-- Case insensitive stop word removal.
        -->
        <filter class="solr.StopFilterFactory"
                ignoreCase="true"
                words="lang/stopwords_en.txt"
                />
		<!-- 在分词和匹配时，考虑 "-"连字符，字母数字的界限，非字母数字字符，这样 "wifi"或"wi fi"都能匹配"Wi-Fi"。 -->
        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
        <filter class="solr.LowerCaseFilterFactory"/>
        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
        <filter class="solr.PorterStemFilterFactory"/>
      </analyzer>
      <analyzer type="query">
        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
		<!-- 同义词 -->
        <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>
        <filter class="solr.StopFilterFactory"
                ignoreCase="true"
                words="lang/stopwords_en.txt"
                />
        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
        <filter class="solr.LowerCaseFilterFactory"/>
        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
        <filter class="solr.PorterStemFilterFactory"/>
      </analyzer>
    </fieldType>

    <!-- Less flexible matching, but less false matches.  Probably not ideal for product names,
         but may be good for SKUs.  Can insert dashes in the wrong place and still match. -->
    <fieldType name="text_en_splitting_tight" class="solr.TextField" positionIncrementGap="100" autoGeneratePhraseQueries="true">
      <analyzer>
        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
        <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="false"/>
        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_en.txt"/>
        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
        <filter class="solr.LowerCaseFilterFactory"/>
        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
        <filter class="solr.EnglishMinimalStemFilterFactory"/>
        <!-- this filter can remove any duplicate tokens that appear at the same position - sometimes
             possible with WordDelimiterFilter in conjuncton with stemming. -->
        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
      </analyzer>
    </fieldType>

    <!-- Just like text_general except it reverses the characters of
	 each token, to enable more efficient leading wildcard queries. -->
    <fieldType name="text_general_rev" class="solr.TextField" positionIncrementGap="100">
      <analyzer type="index">
        <tokenizer class="solr.StandardTokenizerFactory"/>
        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt" />
        <filter class="solr.LowerCaseFilterFactory"/>
        <filter class="solr.ReversedWildcardFilterFactory" withOriginal="true"
           maxPosAsterisk="3" maxPosQuestion="2" maxFractionAsterisk="0.33"/>
      </analyzer>
      <analyzer type="query">
        <tokenizer class="solr.StandardTokenizerFactory"/>
        <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>
        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt" />
        <filter class="solr.LowerCaseFilterFactory"/>
      </analyzer>
    </fieldType>
 
    <fieldType name="alphaOnlySort" class="solr.TextField" sortMissingLast="true" omitNorms="true">
      <analyzer>
        <!-- KeywordTokenizer does no actual tokenizing, so the entire
             input string is preserved as a single token
          -->
        <tokenizer class="solr.KeywordTokenizerFactory"/>
        <!-- The LowerCase TokenFilter does what you expect, which can be
             when you want your sorting to be case insensitive
          -->
        <filter class="solr.LowerCaseFilterFactory" />
        <!-- The TrimFilter removes any leading or trailing whitespace -->
        <filter class="solr.TrimFilterFactory" /> 
        <filter class="solr.PatternReplaceFilterFactory"
                pattern="([^a-z])" replacement="" replace="all"
        />
      </analyzer>
    </fieldType>
 
    <fieldType name="lowercase" class="solr.TextField" positionIncrementGap="100">
      <analyzer>
        <tokenizer class="solr.KeywordTokenizerFactory"/>
        <filter class="solr.LowerCaseFilterFactory" />
      </analyzer>
    </fieldType>
 
    <fieldType name="ignored" stored="false" indexed="false" multiValued="true" class="solr.StrField" />
 
    <fieldType name="point" class="solr.PointType" dimension="2" subFieldSuffix="_d"/>
 
    <fieldType name="location" class="solr.LatLonType" subFieldSuffix="_coordinate"/>
 
    <fieldType name="location_rpt" class="solr.SpatialRecursivePrefixTreeFieldType" geo="true" distErrPct="0.025" maxDistErr="0.001" distanceUnits="kilometers" />
 
    <fieldType name="bbox" class="solr.BBoxField"
               geo="true" distanceUnits="kilometers" numberType="_bbox_coord" />
    <fieldType name="_bbox_coord" class="solr.TrieDoubleField" precisionStep="8" docValues="true" stored="false"/>
 
    <fieldType name="currency" class="solr.CurrencyField" precisionStep="8" defaultCurrency="USD" currencyConfig="currency.xml" />
 
    <fieldType name="splitString" class="solr.TextField">
      <analyzer type="index">
		  <tokenizer class="com.miri.solrLib.analysis.MultiCharTokenizerFactory" delimits="|" />
          <filter class="solr.LowerCaseFilterFactory" />
          <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
	  </analyzer>
	</fieldType>

    <fieldType name="namePinYin" class="solr.TextField" positionIncrementGap="100">
      <analyzer type="index">
        <tokenizer class="solr.KeywordTokenizerFactory"/> 
        <filter class="com.miri.solrLib.SplitTokenFilterFactory"/>
        <filter class="com.miri.solrLib.PinYinFirstCharTokenFilterFactory"/>
        <filter class="com.miri.solrLib.LetterFilterFactory"/>
        <filter class="solr.LowerCaseFilterFactory"/>
      </analyzer>
      <analyzer type="query">
        <tokenizer class="solr.KeywordTokenizerFactory"/>
        <filter class="solr.LowerCaseFilterFactory"/>
      </analyzer>
    </fieldType>
	
</schema>
